{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class gl:\n",
    "    myftype = 'float64'\n",
    "    myitype = 'int64'\n",
    "    k = tf.constant(0.05,dtype=myftype)\n",
    "    M = tf.constant(50,dtype=myitype)\n",
    "    deltat = tf.constant(0.1,dtype=myftype)\n",
    "    numsteps = 3\n",
    "    h = tf.divide(deltat,numsteps)\n",
    "    grid = tf.multiply(k,tf.cast(tf.range(tf.negative(M), tf.add(M, 1), delta=1),dtype=myftype))\n",
    "    gridx, gridy = tf.meshgrid(grid, grid, indexing='ij')\n",
    "    gridsize = tf.add(tf.multiply(M, 2), 1)\n",
    "    gridsize2 = tf.pow(gridsize, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tff(theta, x):\n",
    "    fval = tf.multiply(theta[0],tf.subtract(theta[1],x))\n",
    "    return fval\n",
    "\n",
    "def tfg(theta, x):\n",
    "    gval = tf.multiply(theta[2],tf.ones(tf.shape(x),dtype=gl.myftype))\n",
    "    return gval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integrandmat(inx, iny, th):\n",
    "    my2 = tf.constant(2.0,gl.myftype)\n",
    "    tfmu = tf.add(iny,tf.multiply(tff(theta=th,x=iny),gl.h))\n",
    "    tfsig = tf.multiply(tf.sqrt(gl.h),tfg(theta=th,x=iny))\n",
    "    tfc0 = tf.reciprocal(tf.multiply(tf.sqrt(tf.multiply(my2,tf.constant(np.pi,dtype=gl.myftype))),tfsig))\n",
    "    tfnumer = tf.negative(tf.square(tf.subtract(inx,tfmu)))\n",
    "    tfdenom = tf.multiply(my2,tf.square(tfsig))\n",
    "    tfprop = tf.multiply(tfc0,tf.exp(tf.divide(tfnumer,tfdenom)))\n",
    "    return tfprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dtqall(theta, init, final):\n",
    "    # supposed to be a column vector\n",
    "    lamb = tf.expand_dims(integrandmat(gl.grid, init, theta),1)\n",
    "    \n",
    "    # supposed to be a row vector\n",
    "    gamm = gl.k * tf.expand_dims(integrandmat(final, gl.grid, theta),0)\n",
    "    \n",
    "    # declare two tensors in advance\n",
    "    \n",
    "    lamblist = []\n",
    "    gammlist = []\n",
    "    lamblist.append(lamb)\n",
    "    gammlist.append(gamm)\n",
    "    \n",
    "    for j in range(gl.numsteps-2):\n",
    "        lamblist.append(gl.k*tf.matmul(gl.A,lamblist[j]))\n",
    "        gammlist.append(gl.k*tf.matmul(gammlist[j],gl.A))\n",
    "        \n",
    "    complete = tf.reshape(tf.matmul(gammlist[0],lamblist[gl.numsteps-2]),shape=[])\n",
    "    \n",
    "    # both first and last wil be column vectors\n",
    "    c = tf.multiply(gl.k,complete)\n",
    "    first = tf.divide(tf.multiply(tf.transpose(gammlist[gl.numsteps-2]),lamblist[0]),c)\n",
    "    last = tf.divide(tf.multiply(tf.transpose(gammlist[0]),lamblist[gl.numsteps-2]),c)\n",
    "\n",
    "    # compute all intermediate 2d pdfs\n",
    "    del lamblist[-1]\n",
    "    del gammlist[-1]\n",
    "    lambtensor = tf.stack(lamblist)\n",
    "    # diag = []\n",
    "    # diag.append(tf.shape(lambtensor))\n",
    "    gammtensor = tf.stack(gammlist[::-1])\n",
    "    # diag.append(tf.shape(gammtensor))\n",
    "    A0 = tf.expand_dims(gl.A,0)\n",
    "    # diag.append(tf.shape(A0))\n",
    "    pdf2dlist = tf.transpose(tf.multiply(gammtensor, lambtensor),perm=[0,2,1])\n",
    "    # diag.append(tf.shape(pdf2dlist))\n",
    "    pdf2dlist = tf.multiply(pdf2dlist, A0)\n",
    "    pdf2dlist = tf.divide(pdf2dlist, c)\n",
    "\n",
    "    return complete, first, last, pdf2dlist #, diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logG(x, y, theta):\n",
    "    fv = tff(theta,y)\n",
    "    gv = tfg(theta,y)\n",
    "    mu = tf.add(y,tf.multiply(fv,gl.h))\n",
    "    pr = tf.subtract(x,mu)\n",
    "    pr2 = tf.square(pr)\n",
    "    gv2 = tf.square(gv)\n",
    "    my2 = tf.constant(2.0,dtype=gl.myftype)\n",
    "    mypi = tf.constant(np.pi,dtype=gl.myftype)\n",
    "    lgp1 = tf.negative(tf.divide(tf.log(tf.multiply(my2*mypi*gl.h,gv2)),my2))\n",
    "    lgp2 = tf.negative(tf.divide(pr2,tf.multiply(my2*gl.h,gv2)))\n",
    "    lg = tf.add(lgp1,lgp2)        \n",
    "    return lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allout is the result of a call to dtqall\n",
    "# here x is the data\n",
    "def qfun(theta, allout, init, final):\n",
    "    q = []\n",
    "\n",
    "    # first term in the summation (j=1 case)\n",
    "    part1 = logG(gl.grid,init,theta)\n",
    "    q.append(tf.reduce_sum(tf.multiply(part1,allout[1][:,0]))*gl.k)\n",
    "\n",
    "    # last term in the summation (j=F case)\n",
    "    part2 = logG(final,gl.grid,theta)\n",
    "    q.append(tf.reduce_sum(tf.multiply(part2,allout[2][:,0]))*gl.k)\n",
    "    \n",
    "    # all intermediate terms\n",
    "    part3 = logG(gl.gridx,gl.gridy,theta)\n",
    "    # for j in range(gl.numsteps-2):\n",
    "    #     q.append(tf.tensordot(part3,allout[3][j,:],axes=[[0,1],[0,1]])*gl.k*gl.k)\n",
    "    # test = tf.add_n(test)\n",
    "    \n",
    "    q.append(tf.reduce_sum(tf.multiply(tf.expand_dims(part3,0),allout[3]))*gl.k*gl.k)\n",
    "    \n",
    "    qout = tf.negative(tf.add_n(q))\n",
    "\n",
    "    return qout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(sess.run(qfun(th, allout, init, final), feed_dict = {th : thval}))\n",
    "# print(sess.run(tf.gradients(qfun(th, allout, init, final),th), feed_dict = {th : thval}))\n",
    "# part3 = logG(gl.gridx,gl.gridy,th)\n",
    "# print(sess.run(tf.shape(allout[3][0,:]), feed_dict = {th : thval}))\n",
    "# print(sess.run(tf.tensordot(part3,allout[3][0,:],axes=[[0,1],[0,1]]), feed_dict = {th : thval}))\n",
    "# print(sess.run(fir, feed_dict = {th : thval}))\n",
    "# print(sess.run(gl.k*gl.k*tf.reduce_sum(pdf,axis=[1,2]), feed_dict = {th : thval}))\n",
    "# print(sess.run(tf.gradients(logG(gl.gridx,gl.gridy,th),th),  feed_dict = {th : thval}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load simulated data from the file\n",
    "import csv\n",
    "datain = []\n",
    "with open('simdata.csv', newline='') as f:\n",
    "    reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader:\n",
    "        datain.append(row)\n",
    "        \n",
    "xt = np.array(datain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrow = xt.shape[0]\n",
    "pairs = np.vstack([xt[0:(nrow-1),0],xt[1:nrow,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start with some initial theta, call that thetak\n",
    "thval = [0.5,0.7,0.2]\n",
    "def dtqallwrap(onepair):\n",
    "    return dtqall(theta=gl.thetak,init=onepair[0],final=onepair[1])\n",
    "\n",
    "def myloss(th, allallouts, pairs):\n",
    "    newlist = []\n",
    "    for i in range(len(pairs)):\n",
    "        newlist.append([allallouts[i],pairs[i]])\n",
    "    \n",
    "    temp = [qfun(th, x[0], x[1][0], x[1][1]) for x in newlist]\n",
    "    qout = tf.reduce_sum(temp)\n",
    "    # qout = tf.Variable(tf.constant(0.,dtype=gl.myftype))\n",
    "    #qout = tf.constant(0.,dtype=gl.myftype)\n",
    "    #for i in range(len(pairs)):\n",
    "    #    qout += qfun(th,allallouts[i],pairs[i][0],pairs[i][1])\n",
    "        \n",
    "    return qout\n",
    "\n",
    "emiters = 1\n",
    "# for emi in range(emiters):\n",
    "# E step\n",
    "gl.thetak = tf.constant(thval,dtype=gl.myftype)\n",
    "gl.A = integrandmat(gl.gridx, gl.gridy, gl.thetak)\n",
    "allallouts = sess.run(list(map(dtqallwrap, pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668.23197796\n"
     ]
    }
   ],
   "source": [
    "# M step\n",
    "# define the actual q function\n",
    "th = tf.Variable(gl.thetak)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loss = myloss(th, allallouts, pairs)\n",
    "print(sess.run(loss))\n",
    "\n",
    "# optimize the loss\n",
    "learning_rate = 0.001\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = my_opt.minimize(loss)\n",
    "sess.run(train_step)\n",
    "print(sess.run(loss))\n",
    "\n",
    "# optimize the loss\n",
    "learning_rate = 0.01\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = my_opt.minimize(loss)\n",
    "for i in range(250):\n",
    "    sess.run(train_step)\n",
    "\n",
    "print(sess.run(loss))\n",
    "\n",
    "# all of the above completes the E step\n",
    "\n",
    "# 3) implement the optimization loop (M step)\n",
    "\n",
    "# 4) run some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.67741859,  1.49498079,  1.03529161])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.85998963281\n",
      "-4.83433050212\n",
      "-5.01460321911\n",
      "-5.10189527668\n",
      "-5.15133405785\n",
      "-5.18021195576\n",
      "-5.19695760363\n",
      "-5.2065969103\n",
      "-5.21212087243\n",
      "-5.21527816983\n",
      "-5.21707996509\n",
      "-5.21810725073\n",
      "-5.21869262214\n",
      "-5.21902606413\n",
      "-5.21921595929\n",
      "-5.21932408937\n",
      "-5.21938565514\n",
      "-5.21942070655\n",
      "-5.21944066165\n",
      "-5.21945202194\n"
     ]
    }
   ],
   "source": [
    "th = tf.Variable(thetak)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loss = qfun(th, allout, init, final)\n",
    "learning_rate = 0.001\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = my_opt.minimize(loss)\n",
    "for i in range(1000):\n",
    "    sess.run(train_step)\n",
    "    if (i % 50)==0:\n",
    "        print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77364992  0.36753552  0.20304843]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  -3. ]\n",
      " [-1.5  4.5]]\n",
      "[[ 2.  -3. ]\n",
      " [-1.5  4.5]]\n"
     ]
    }
   ],
   "source": [
    "q = tf.Variable(np.array([[2.0,-3.0],[-1.5,4.5]]))\n",
    "inc = tf.constant(np.array([[0.0,1.0],[0.0,0.0]]))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(q))\n",
    "tf.assign_add(q, inc)\n",
    "print(sess.run(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUTURE WORK:\n",
    "# replace the G function with the Anderson-Mattingly G (integrandmat and logG)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
