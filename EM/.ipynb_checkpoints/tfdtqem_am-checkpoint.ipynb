{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class gl:\n",
    "    myftype = 'float64'\n",
    "    myitype = 'int64'\n",
    "    k = tf.constant(0.1, dtype = myftype)\n",
    "    M = tf.constant(50, dtype = myitype)\n",
    "    deltat = tf.constant(0.1, dtype = myftype)\n",
    "    numsteps = 10\n",
    "    h = tf.constant(0.5, dtype = myftype)\n",
    "    grid = tf.multiply(k,tf.cast(tf.range(tf.negative(M), tf.add(M, 1), delta = 1), dtype = myftype))\n",
    "    gridx, gridy = tf.meshgrid(grid, grid, indexing = 'ij')\n",
    "    gridsize = tf.add(tf.multiply(M, 2), 1)\n",
    "    gridsize2 = tf.pow(gridsize, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tff(theta, x):\n",
    "    fval = tf.multiply(theta[0],tf.subtract(theta[1],x))\n",
    "    return fval\n",
    "\n",
    "def tfg(theta, x):\n",
    "    gval = tf.multiply(theta[2],tf.ones(tf.shape(x),dtype=gl.myftype))\n",
    "    return gval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def integrandmat(inx, iny, th):\n",
    "#     my2 = tf.constant(2.0,gl.myftype)\n",
    "#     tfmu = tf.add(iny,tf.multiply(tff(theta=th,x=iny),gl.h))\n",
    "#     tfsig = tf.multiply(tf.sqrt(gl.h),tfg(theta=th,x=iny))\n",
    "#     tfc0 = tf.reciprocal(tf.multiply(tf.sqrt(tf.multiply(my2,tf.constant(np.pi,dtype=gl.myftype))),tfsig))\n",
    "#     tfnumer = tf.negative(tf.square(tf.subtract(inx,tfmu)))\n",
    "#     tfdenom = tf.multiply(my2,tf.square(tfsig))\n",
    "#     tfprop = tf.multiply(tfc0,tf.exp(tf.divide(tfnumer,tfdenom)))\n",
    "#     return tfprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createAB(theta):\n",
    "    AMtheta = tf.constant(0.5, dtype = gl.myftype)\n",
    "    omtheta = tf.subtract(tf.constant(1.0, dtype = gl.myftype), AMtheta)\n",
    "    alpha = []\n",
    "    alpha.append(tf.div(tf.constant(0.5, dtype = gl.myftype), tf.multiply(AMtheta, omtheta)))\n",
    "    alpha.append(tf.multiply(alpha[0], tf.add(tf.square(AMtheta), tf.square(omtheta))))\n",
    "    \n",
    "    outAval = tf.zeros(shape = 1, dtype = gl.myftype)\n",
    "    outAind = tf.zeros(shape = (1,3), dtype = gl.myitype)\n",
    "    Aval = [outAval]\n",
    "    Aind = [outAind]\n",
    "    \n",
    "    fvec = f(theta, grid)\n",
    "    gvec = g(theta, grid)\n",
    "    \n",
    "    g2m1 = tf.square(gvec)\n",
    "    col1 = tf.ones(shape = (gl.gridsize, 1), dtype = gl.myitype)\n",
    "    colr = tf.reshape(tf.cast(tf.range(0, gl.gridsize, delta = 1), dtype = gl.myitype), (gl.gridsize, 1))\n",
    "    \n",
    "    for i in range(gl.gridsize):\n",
    "        for j in range(gl.gridsize):\n",
    "            if (tf.abs(tf.subtract(i,j)) > np.inf):\n",
    "                continue\n",
    "\n",
    "            yi = grid[i]\n",
    "            ystar = grid[j]\n",
    "            mv = tf.add(ystar, tf.multiply(tf.subtract((tf.multiply(alpha[0], f(th, ystar)), tf.multiply(alpha[1], fvec))), tf.multiply(omtheta, gl.h)))\n",
    "            g2star = tf.square(g(th, ystar))\n",
    "            vv = tf.maximum(0, alpha[0]*g2star - alpha[1]*g2m1)*omtheta*gl.h\n",
    "                        \n",
    "            # the original code used scale = np.sqrt(vv) but scale is \\sigma^2, here it's \\sigma\n",
    "            # confirm which one has to be used!\n",
    "            thesepdfs = tf.contrib.distributions.Normal(mu = mv, sigma = tf.sqrt(vv))\n",
    "            thesevals = thesepdfs.pdf(yi)\n",
    "            \n",
    "            indblock = tf.concat([i*col1,j*col1,colr], axis = 1)\n",
    "            Aind.append(indblock)\n",
    "            Aval.append(thesevals)\n",
    "    \n",
    "    # np.hstack(vec) == tf.concat(vec, axis = 1)\n",
    "    # np.vstack(vec) == tf.concat(vec, axis = 0)\n",
    "    outAind = tf.concat(Aind[1:], axis = 0)\n",
    "    outAval = tf.concat(Aval[1:], axis = 1)\n",
    "\n",
    "    Bds = [gl.gridsize, gl.gridsize]\n",
    "    Bind = tf.zeros((0,2), dtype = gl.myitype)\n",
    "    thisvar = g2m1 * AMtheta * gl.h\n",
    "    c0mod = tf.div(tf.constant(1., dtype = gl.myftype), tf.sqrt(tf.constant(2., dtype = gl.myftype)*np.pi*thisvar))\n",
    "    propvals = tf.exp(tf.negative(AMtheta*gl.h/2.0)*tf.square(fvec)/g2m1) * c0mod\n",
    "    Bval = [propvals]\n",
    "    indblock = tf.concat([colr, colr], axis = 1)\n",
    "    Bind = [tf.concat([Bind, indblock], axis = 0)]\n",
    "\n",
    "    for curdiag in range(1, gl.gridsize):\n",
    "        thislen = gl.gridsize - curdiag\n",
    "        mymean = curdiag * gl.k + fvec * gl.h * AMtheta\n",
    "        thisdiag = tf.exp(-tf.square(mymean)/(2.0*thisvar)) * c0mod\n",
    "        thisdiag = thisdiag[-thislen:]\n",
    "        indblock = tf.concat([colr[:(gl.gridsize - curdiag)], (colr[:(gl.gridsize - curdiag)] + curdiag)], axis = 1)\n",
    "        Bind.append(indblock) \n",
    "        Bval.append(thisdiag) \n",
    "\n",
    "    for curdiag in range(1, gl.gridsize):\n",
    "        thislen = gl.gridsize - curdiag\n",
    "        mymean = -curdiag * gl.k + fvec * gl.h * AMtheta\n",
    "        thisdiag = tf.exp(-tf.square(mymean)/(2.0*thisvar)) * c0mod\n",
    "        thisdiag = thisdiag[:thislen]\n",
    "        indblock = tf.concat([(colr[:(gl.gridsize - curdiag)] + curdiag), colr[:(gl.gridsize - curdiag)]], axis = 1)\n",
    "        Bind.append(indblock) \n",
    "        Bval.append(thisdiag) \n",
    "\n",
    "    outBind = tf.concat(Bind, axis = 0)\n",
    "    outBval = tf.concat(Bval, axis = 1)\n",
    "    \n",
    "    return outAind, outAval, outBind, outBval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeAMprop(Aind, Aval, Bden):\n",
    "    sortAind = np.argsort(Aind[:,2])\n",
    "    newAind = Aind[sortAind,:]\n",
    "    newAval = tf.array(Aval)\n",
    "    newAval = newAval[sortAind]\n",
    "    mypropcols = []\n",
    "    startind = 0\n",
    "    thisds = [gl.gridsize, gl.gridsize]\n",
    "    for j in range(gl.gridsize):\n",
    "        if j == (gl.gridsize-1):\n",
    "            endind = len(Aval)\n",
    "        else:\n",
    "            endind = np.searchsorted(newAind[:,2],(j+1))\n",
    "\n",
    "        thesevals = newAval[startind:endind]\n",
    "        theseinds = newAind[startind:endind,0:2]\n",
    "        thisten = tf.SparseTensor(indices = theseinds, values = thesevals, dense_shape = thisds)\n",
    "        newcolumn = (gl.k)*tf.sparse_tensor_dense_matmul(thisten, tf.slice(Bden, [0,j], [gl.gridsize,1]))\n",
    "        mypropcols.append(newcolumn[:,0])\n",
    "        startind = endind\n",
    "\n",
    "    myprop = tf.stack(mypropcols)\n",
    "    return myprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integrandmat():\n",
    "    Aind, Aval, Bind, Bval = createAB(tol = np.inf)\n",
    "    Bds = [gl.gridsize, gl.gridsize]\n",
    "    Bten = tf.SparseTensor(indices = Bind, values = Bval, dense_shape = Bds)\n",
    "    Bden = tf.sparse_tensor_to_dense(Bten, validate_indices = False)\n",
    "    prop = computeAMprop(Aind, Aval, Bden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dtqall(theta, init, final):\n",
    "    # supposed to be a column vector\n",
    "    lamb = tf.expand_dims(integrandmat(gl.grid, init, theta),1)\n",
    "    \n",
    "    # supposed to be a row vector\n",
    "    gamm = gl.k * tf.expand_dims(integrandmat(final, gl.grid, theta),0)\n",
    "    \n",
    "    # declare two tensors in advance\n",
    "    \n",
    "    lamblist = []\n",
    "    gammlist = []\n",
    "    lamblist.append(lamb)\n",
    "    gammlist.append(gamm)\n",
    "    \n",
    "    for j in range(gl.numsteps-2):\n",
    "        lamblist.append(gl.k*tf.matmul(gl.A,lamblist[j]))\n",
    "        gammlist.append(gl.k*tf.matmul(gammlist[j],gl.A))\n",
    "        \n",
    "    complete = tf.reshape(tf.matmul(gammlist[0],lamblist[gl.numsteps-2]),shape=[])\n",
    "    \n",
    "    # both first and last wil be column vectors\n",
    "    c = tf.multiply(gl.k,complete)\n",
    "    first = tf.divide(tf.multiply(tf.transpose(gammlist[gl.numsteps-2]),lamblist[0]),c)\n",
    "    last = tf.divide(tf.multiply(tf.transpose(gammlist[0]),lamblist[gl.numsteps-2]),c)\n",
    "\n",
    "    # compute all intermediate 2d pdfs\n",
    "    del lamblist[-1]\n",
    "    del gammlist[-1]\n",
    "    lambtensor = tf.stack(lamblist)\n",
    "    # diag = []\n",
    "    # diag.append(tf.shape(lambtensor))\n",
    "    gammtensor = tf.stack(gammlist[::-1])\n",
    "    # diag.append(tf.shape(gammtensor))\n",
    "    A0 = tf.expand_dims(gl.A,0)\n",
    "    # diag.append(tf.shape(A0))\n",
    "    pdf2dlist = tf.transpose(tf.multiply(gammtensor, lambtensor),perm=[0,2,1])\n",
    "    # diag.append(tf.shape(pdf2dlist))\n",
    "    pdf2dlist = tf.multiply(pdf2dlist, A0)\n",
    "    pdf2dlist = tf.divide(pdf2dlist, c)\n",
    "\n",
    "    return complete, first, last, pdf2dlist #, diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logG(x, y, theta):\n",
    "    fv = tff(theta,y)\n",
    "    gv = tfg(theta,y)\n",
    "    mu = tf.add(y,tf.multiply(fv,gl.h))\n",
    "    pr = tf.subtract(x,mu)\n",
    "    pr2 = tf.square(pr)\n",
    "    gv2 = tf.square(gv)\n",
    "    my2 = tf.constant(2.0,dtype=gl.myftype)\n",
    "    mypi = tf.constant(np.pi,dtype=gl.myftype)\n",
    "    lgp1 = tf.negative(tf.divide(tf.log(tf.multiply(my2*mypi*gl.h,gv2)),my2))\n",
    "    lgp2 = tf.negative(tf.divide(pr2,tf.multiply(my2*gl.h,gv2)))\n",
    "    lg = tf.add(lgp1,lgp2)        \n",
    "    return lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allout is the result of a call to dtqall\n",
    "# here x is the data\n",
    "def qfun(theta, allout, init, final):\n",
    "    q = []\n",
    "\n",
    "    # first term in the summation (j=1 case)\n",
    "    part1 = logG(gl.grid,init,theta)\n",
    "    q.append(tf.reduce_sum(tf.multiply(part1,allout[1][:,0]))*gl.k)\n",
    "\n",
    "    # last term in the summation (j=F case)\n",
    "    part2 = logG(final,gl.grid,theta)\n",
    "    q.append(tf.reduce_sum(tf.multiply(part2,allout[2][:,0]))*gl.k)\n",
    "    \n",
    "    # all intermediate terms\n",
    "    part3 = logG(gl.gridx,gl.gridy,theta)\n",
    "    # for j in range(gl.numsteps-2):\n",
    "    #     q.append(tf.tensordot(part3,allout[3][j,:],axes=[[0,1],[0,1]])*gl.k*gl.k)\n",
    "    # test = tf.add_n(test)\n",
    "    \n",
    "    q.append(tf.reduce_sum(tf.multiply(tf.expand_dims(part3,0),allout[3]))*gl.k*gl.k)\n",
    "    \n",
    "    qout = tf.negative(tf.add_n(q))\n",
    "\n",
    "    return qout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([0]) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/home/shagun/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 267\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    268\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shagun/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2404\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2405\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shagun/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2493\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[0;32m-> 2494\u001b[0;31m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4bd800ebf18e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyftype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyftype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegrandmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mallout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtqall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# all of the above completes the E step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4464d557b362>\u001b[0m in \u001b[0;36mintegrandmat\u001b[0;34m(Aind, Aval, Bden)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mintegrandmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msortAind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msortAind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnewAind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortAind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnewAval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shagun/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shagun/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shagun/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \"\"\"\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shagun/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/home/shagun/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    269\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    270\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    272\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([0]) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "thval = [0.5,0.7,0.2]\n",
    "thetak = tf.constant(thval,dtype=gl.myftype)\n",
    "init = tf.constant(0.01,dtype=gl.myftype)\n",
    "final = tf.constant(0.2,dtype=gl.myftype)\n",
    "gl.A = integrandmat(gl.gridx, gl.gridy, thetak)\n",
    "allout = dtqall(thetak, init, final)\n",
    "# all of the above completes the E step\n",
    "\n",
    "# print(sess.run(qfun(th, allout, init, final), feed_dict = {th : thval}))\n",
    "# print(sess.run(tf.gradients(qfun(th, allout, init, final),th), feed_dict = {th : thval}))\n",
    "# part3 = logG(gl.gridx,gl.gridy,th)\n",
    "# print(sess.run(tf.shape(allout[3][0,:]), feed_dict = {th : thval}))\n",
    "# print(sess.run(tf.tensordot(part3,allout[3][0,:],axes=[[0,1],[0,1]]), feed_dict = {th : thval}))\n",
    "# print(sess.run(fir, feed_dict = {th : thval}))\n",
    "# print(sess.run(gl.k*gl.k*tf.reduce_sum(pdf,axis=[1,2]), feed_dict = {th : thval}))\n",
    "# print(sess.run(tf.gradients(logG(gl.gridx,gl.gridy,th),th),  feed_dict = {th : thval}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "th = tf.Variable(thetak)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loss = qfun(th, allout, init, final)\n",
    "learning_rate = 0.05\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = tf.Variable(np.array([[2.0,-3.0],[-1.5,4.5]]))\n",
    "inc = tf.constant(np.array([[0.0,1.0],[0.0,0.0]]))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(q))\n",
    "tf.assign_add(q, inc)\n",
    "print(sess.run(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
